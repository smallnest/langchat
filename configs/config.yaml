server:
  host: "localhost"
  port: 8080
  read_timeout: 30s
  write_timeout: 30s
  idle_timeout: 120s

agent:
  max_concurrent: 50
  max_idle_time: 30m
  health_check_interval: 30s
  max_retries: 3
  retry_delay: 5s
  session_timeout: 60m
  max_history: 100

llm:
  provider: "openai"
  model: "deepseek-v3"
  api_key: ""
  temperature: 0.7
  max_tokens: 4096
  timeout: 60s

security:
  jwt_secret: "your-secret-key"
  session_timeout: 24h
  rate_limit_enabled: true
  rate_limit_rps: 10
  cors_enabled: true

monitoring:
  enabled: true
  metrics_port: 9090
  tracing_enabled: false
  health_check_enabled: true

logging:
  level: "info"
  format: "json"
  output: "stdout"

cache:
  type: "memory"
  ttl: 1h
  max_size: 1000

features:
  artifacts_enabled: true
  tools_enabled: true
  websocket_enabled: true